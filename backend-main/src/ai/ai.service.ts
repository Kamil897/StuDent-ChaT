import {
  Injectable,
  InternalServerErrorException,
  BadRequestException,
} from '@nestjs/common';
import { HttpService } from '@nestjs/axios';
import * as fs from 'fs';
import * as path from 'path';
import OpenAI from 'openai';

@Injectable()
export class AiService {
  private client: OpenAI;
  private memory: Record<string, Array<{ role: string; content: string }>> = {};
  private memoryPath = path.resolve(process.cwd(), 'memory.json');

  constructor(private readonly httpService: HttpService) {
    this.client = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY, // üîë API-–∫–ª—é—á –∏–∑ .env
    });
  }

  // =========================
  // üî§ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞
  // =========================
  private detectLanguage(text: string): 'ru' | 'en' | 'other' {
    if (/[–∞-—è–ê-–Ø—ë–Å]/.test(text)) return 'ru';
    if (/[a-zA-Z]/.test(text)) return 'en';
    return 'other';
  }

  private systemPromptByLang(lang: 'ru' | 'en' | 'other'): string {
    if (lang === 'ru') {
      return `
      –¢—ã ‚Äî —Ü–∏—Ñ—Ä–æ–≤–æ–π —É—á–µ–±–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç Cognia –æ—Ç –∫–æ–º–ø–∞–Ω–∏–∏ Student-Chat.
      –û—Ç–≤–µ—á–∞–π –í–°–ï–ì–î–ê –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
      –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π —Ç–µ–º—É: –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ, —ç–∫–∑–∞–º–µ–Ω—ã, —è–∑—ã–∫–∏, –º–∞—Ç–µ–º–∞—Ç–∏–∫–∞, –ò–¢.
      –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –≤–Ω–µ —Ç–µ–º–∞—Ç–∏–∫–∏ ‚Äî –º—è–≥–∫–æ –æ—Ç–∫–ª–æ–Ω—è–π.
      `.trim();
    }
    if (lang === 'en') {
      return `
    You are Cognia, a digital learning assistant by Student-Chat.
    Always respond in English.
    Keep the scope: education, exams, languages, math, IT.
    Reject unrelated topics.
      `.trim();
    }
    return `
    You are Cognia, a multilingual learning assistant by Student-Chat.
    Answer in the user's language. Focus only on education/IT/exams/languages/math.
    Reject unrelated topics.
    `.trim();
  }

  // =========================
  // ‚¨áÔ∏è –§–∏–ª—å—Ç—Ä —Å—Ç–∏–ª—è/–¥–æ–º–µ–Ω–∞
  // =========================
  private enforceStyleAndDomain(message: string): string {
    const offTopic = [
      '–ø–æ–ª–∏—Ç–∏–∫',
      '–ø–æ–ª–∏—Ç–∏–∫–∞',
      '18+',
      '–ø–æ—Ä–Ω–æ',
      '–æ—Ä—É–∂',
      '–±–∏—Ä–∂–∞',
      '—Å—Ç–∞–≤–∫',
      '–∫–∞–∑–∏–Ω–æ',
      '–≤–∑–ª–æ–º',
      '—Ö–∞–∫–∏–Ω–≥',
      '–Ω–∞—Ä–∫–æ—Ç',
      '–±–æ–º–±',
      '—Ç–µ—Ä—Ä–æ—Ä',
      '—Ä–µ–ª–∏–≥',
      '—Ä–µ—Ü–µ–ø—Ç',
      '–∞–Ω–µ–∫–¥–æ—Ç',
      '–Ω–æ–≤–æ—Å—Ç',
    ];
    if (offTopic.some((k) => message.toLowerCase().includes(k))) {
      throw new BadRequestException(
        '–í–æ–ø—Ä–æ—Å –Ω–µ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ —Ç–µ–º–µ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è/–ò–¢.',
      );
    }

    return `
    –¢—ã ‚Äî Cognia (Student-Chat).
    –û—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ –≤ —Ä–∞–º–∫–∞—Ö: –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ, –ò–¢, —ç–∫–∑–∞–º–µ–Ω—ã, —è–∑—ã–∫–∏, –º–∞—Ç–µ–º–∞—Ç–∏–∫–∞.
    –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
    1) –®–∞–≥–∏ –æ–±—É—á–µ–Ω–∏—è –∏–ª–∏ –∞–ª–≥–æ—Ä–∏—Ç–º.
    2) –ú–∏–Ω–∏-–ø—Ä–∏–º–µ—Ä / –∑–∞–¥–∞–Ω–∏–µ –¥–ª—è –ø—Ä–∞–∫—Ç–∏–∫–∏.
    –ï—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω ‚Äî —Å–∫–∞–∂–∏ "–Ω–µ —É–≤–µ—Ä–µ–Ω, —É—Ç–æ—á–Ω–∏—Ç–µ".
    ---
    –í–æ–ø—Ä–æ—Å: ${message}
    –û—Ç–≤–µ—Ç:
    `.trim();
  }

  // =========================
  // üìÇ –ü–∞–º—è—Ç—å JSON
  // =========================
  private ensureMemoryFile() {
    if (!fs.existsSync(this.memoryPath)) {
      fs.writeFileSync(this.memoryPath, JSON.stringify([]), 'utf-8');
    }
  }

  private readMemory(): Array<{ q: string; a: string }> {
    this.ensureMemoryFile();
    try {
      return JSON.parse(fs.readFileSync(this.memoryPath, 'utf-8'));
    } catch {
      return [];
    }
  }

  private writeMemory(items: Array<{ q: string; a: string }>) {
    fs.writeFileSync(this.memoryPath, JSON.stringify(items, null, 2), 'utf-8');
  }

  private similarity(a: string, b: string): number {
    const sa = new Set(a.toLowerCase().split(/\W+/).filter(Boolean));
    const sb = new Set(b.toLowerCase().split(/\W+/).filter(Boolean));
    const inter = [...sa].filter((x) => sb.has(x)).length;
    const union = new Set([...sa, ...sb]).size || 1;
    return inter / union;
  }

  private searchMemory(query: string, threshold = 0.6): string | null {
    const mem = this.readMemory();
    let best: { a: string; score: number } | null = null;
    for (const item of mem) {
      const s = this.similarity(query, item.q);
      if (!best || s > best.score) best = { a: item.a, score: s };
    }
    return best && best.score >= threshold ? best.a : null;
  }

  private saveToMemory(q: string, a: string) {
    if (!q || !a) return;
    const mem = this.readMemory();
    mem.push({ q, a });
    if (mem.length > 500) mem.splice(0, mem.length - 500);
    this.writeMemory(mem);
  }

  // =========================
  // ü§ù GPT-4 —Å –ø–∞–º—è—Ç—å—é
  // =========================
  async askGPT4(
    message: string,
    persona?: string,
  ): Promise<{ reply: string; source: 'memory' | 'model' }> {
    const cached = this.searchMemory(message, 0.6);
    if (cached) return { reply: cached, source: 'memory' };

    const filteredPrompt = this.enforceStyleAndDomain(
      persona ? `${persona}\n\n${message}` : message,
    );

    try {
      const lang = this.detectLanguage(message);
      const systemPrompt = persona || this.systemPromptByLang(lang);

      const completion = await this.client.chat.completions.create({
        model: 'gpt-4.1-nano', // –º–æ–∂–Ω–æ 'gpt-4o-mini' –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: filteredPrompt },
        ],
        temperature: 0.3,
      });

      const reply =
        completion.choices[0].message?.content?.trim() || '–ù–µ—Ç –æ—Ç–≤–µ—Ç–∞';
      this.saveToMemory(message, reply);
      return { reply, source: 'model' };
    } catch (error: any) {
      console.error('GPT-4 Error:', error.response?.data || error.message);
      throw new InternalServerErrorException('GPT-4 service failed');
    }
  }

  // =========================
  // üåä Streaming GPT-4
  // =========================
  async askGPT4Stream(
    message: string,
    onChunk: (chunk: string) => void,
    persona?: string,
  ): Promise<void> {
    const cached = this.searchMemory(message, 0.6);
    if (cached) {
      onChunk(cached);
      return;
    }

    const filteredPrompt = this.enforceStyleAndDomain(
      persona ? `${persona}\n\n${message}` : message,
    );
    const lang = this.detectLanguage(message);
    const systemPrompt = persona || this.systemPromptByLang(lang);

    try {
      const stream = await this.client.chat.completions.create({
        model: 'gpt-4o',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: filteredPrompt },
        ],
        temperature: 0.3,
        stream: true,
      });

      let full = '';
      for await (const chunk of stream) {
        const delta = chunk.choices[0]?.delta?.content || '';
        if (delta) {
          full += delta;
          onChunk(delta);
        }
      }

      if (full.trim()) {
        this.saveToMemory(message, full.trim());
      }
    } catch (error: any) {
      console.error(
        'GPT-4 Stream Error:',
        error.response?.data || error.message,
      );
      throw new InternalServerErrorException('GPT-4 stream failed');
    }
  }

  // =========================
  // üõ°Ô∏è SAFE: Memory ‚Üí GPT-4 ‚Üí fallback
  // =========================
  async askAISafe(message: string, persona?: string) {
    const cached = this.searchMemory(message, 0.6);
    if (cached) return { reply: cached, source: 'memory' };

    try {
      const { reply } = await this.askGPT4(message, persona);
      return { reply, source: 'model' as const };
    } catch (e) {
      console.error('Model failed:', e);
    }

    const lang = this.detectLanguage(message);
    const fallback =
      lang === 'ru'
        ? '–°–µ–π—á–∞—Å –Ω–µ –º–æ–≥—É –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.'
        : 'I cannot fetch an answer right now. Please try again later.';
    return { reply: fallback, source: 'fallback' as const };
  }

  async askAIStreamSafe(
    message: string,
    onChunk: (chunk: string) => void,
    persona?: string,
  ) {
    const cached = this.searchMemory(message, 0.6);
    if (cached) {
      onChunk(cached);
      return;
    }

    try {
      await this.askGPT4Stream(message, onChunk, persona);
    } catch (e) {
      console.error('Stream failed:', e);
      const lang = this.detectLanguage(message);
      const fallback =
        lang === 'ru'
          ? '–°–µ–π—á–∞—Å –Ω–µ –º–æ–≥—É –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.'
          : 'I cannot fetch an answer right now. Please try again later.';
      onChunk(fallback);
    }
  }

  // =========================
  // üî• –ú–µ—Ç–æ–¥: ask —Å userId + history
  // =========================
  async ask(userId: string, message: string, style: string, history?: any[]) {
    if (history) {
      this.memory[userId] = history.map((m) => ({
        role: m.role,
        content: m.text,
      }));
    }
    if (!this.memory[userId]) this.memory[userId] = [];
    this.memory[userId].push({ role: 'user', content: message });

    const persona = style
      ? `${style}\n\n${this.systemPromptByLang(this.detectLanguage(message))}`
      : undefined;
    const { reply, source } = await this.askAISafe(message, persona);

    this.memory[userId].push({ role: 'assistant', content: reply });
    return { reply, source, history: this.memory[userId] };
  }
}
